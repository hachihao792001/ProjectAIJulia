struct MGPolicy
	p # dictionary mapping states to simple game policies
	MGPolicy(p::Base.Generator) = new(Dict(p))
end

(Ï€i::MGPolicy)(s, ai) = Ï€i.p[s](ai)
(Ï€i::SimpleGamePolicy)(s, ai) = Ï€i(ai)

probability(ð’«::MG, s, Ï€, a) = prod(Ï€j(s, aj) for (Ï€j, aj) in zip(Ï€, a))
reward(ð’«::MG, s, Ï€, i) =
	sum(ð’«.R(s,a)[i]*probability(ð’«,s,Ï€,a) for a in joint(ð’«.ð’œ))
transition(ð’«::MG, s, Ï€, sâ€²) =
	sum(ð’«.T(s,a,sâ€²)*probability(ð’«,s,Ï€,a) for a in joint(ð’«.ð’œ))

function policy_evaluation(ð’«::MG, Ï€, i)
	ð’®, ð’œ, R, T, Î³ = ð’«.ð’®, ð’«.ð’œ, ð’«.R, ð’«.T, ð’«.Î³
	p(s,a) = prod(Ï€j(s, aj) for (Ï€j, aj) in zip(Ï€, a))
	Râ€² = [sum(R(s,a)[i]*p(s,a) for a in joint(ð’œ)) for s in ð’®]
	Tâ€² = [sum(T(s,a,sâ€²)*p(s,a) for a in joint(ð’œ)) for s in ð’®, sâ€² in ð’®]
	return (I - Î³*Tâ€²)\Râ€²
end

function best_response(ð’«::MG, Ï€, i)
	ð’®, ð’œ, R, T, Î³ = ð’«.ð’®, ð’«.ð’œ, ð’«.R, ð’«.T, ð’«.Î³
	Tâ€²(s,ai,sâ€²) = transition(ð’«, s, joint(Ï€, SimpleGamePolicy(ai), i), sâ€²)
	Râ€²(s,ai) = reward(ð’«, s, joint(Ï€, SimpleGamePolicy(ai), i), i)
	Ï€i = solve(MDP(Î³, ð’®, ð’œ[i], Tâ€², Râ€²))
	return MGPolicy(s => SimpleGamePolicy(Ï€i(s)) for s in ð’®)
end

function softmax_response(ð’«::MG, Ï€, i, Î»)
	ð’®, ð’œ, R, T, Î³ = ð’«.ð’®, ð’«.ð’œ, ð’«.R, ð’«.T, ð’«.Î³
	Tâ€²(s,ai,sâ€²) = transition(ð’«, s, joint(Ï€, SimpleGamePolicy(ai), i), sâ€²)
	Râ€²(s,ai) = reward(ð’«, s, joint(Ï€, SimpleGamePolicy(ai), i), i)
	mdp = MDP(Î³, ð’®, joint(ð’œ), Tâ€², Râ€²)
	Ï€i = solve(mdp)
	Q(s,a) = lookahead(mdp, Ï€i.U, s, a)
	p(s) = SimpleGamePolicy(a => exp(Î»*Q(s,a)) for a in ð’œ[i])
	return MGPolicy(s => p(s) for s in ð’®)
end

struct PredatorPreyHexWorldMG
    hexes::Vector{Tuple{Int, Int}}
    hexWorldDiscreteMDP::DiscreteMDP
end

n_agents(mg::PredatorPreyHexWorldMG) = 2

ordered_states(mg::PredatorPreyHexWorldMG, i::Int) = vec(collect(1:length(mg.hexes)))
ordered_states(mg::PredatorPreyHexWorldMG) = vec(collect(Iterators.product([ordered_states(mg, i) for i in 1:n_agents(mg)]...)))

ordered_actions(mg::PredatorPreyHexWorldMG, i::Int) = vec(collect(1:n_actions(mg.hexWorldDiscreteMDP)))
ordered_joint_actions(mg::PredatorPreyHexWorldMG) = vec(collect(Iterators.product([ordered_actions(mg, i) for i in 1:n_agents(mg)]...)))

n_actions(mg::PredatorPreyHexWorldMG, i::Int) = length(ordered_actions(mg, i))
n_joint_actions(mg::PredatorPreyHexWorldMG) = length(ordered_joint_actions(mg))

function transition(mg::PredatorPreyHexWorldMG, s, a, sâ€²)
    # When a prey is caught (new prey born), it teleports to a random location and the predator remains (eating).
    # Otherwise, both transition following HexWorldMDP.
    if s[1] == s[2]
        prob = Float64(sâ€²[1] == s[1]) / length(mg.hexes)
    else
        prob = mg.hexWorldDiscreteMDP.T[s[1], a[1], sâ€²[1]] * mg.hexWorldDiscreteMDP.T[s[2], a[2], sâ€²[2]]
    end
    return prob
end

function reward(mg::PredatorPreyHexWorldMG, i::Int, s, a)
    r = 0.0

    if i == 1
        # Predators get -1 for moving and 10 for catching the prey.
        if s[1] == s[2]
            return 10.0
        else
            return -1.0
        end
    elseif i == 2
        # Prey get -1 for moving and -100 for being caught.
        if s[1] == s[2]
            r = -100.0
        else
            r = -1.0
        end
    end

    return r
end

function joint_reward(mg::PredatorPreyHexWorldMG, s, a)
    return [reward(mg, i, s, a) for i in 1:n_agents(mg)]
end

function MG(mg::PredatorPreyHexWorldMG)
    return MG(
        mg.hexWorldDiscreteMDP.Î³,
        vec(collect(1:n_agents(mg))),
        ordered_states(mg),
        [ordered_actions(mg, i) for i in 1:n_agents(mg)],
        (s, a, sâ€²) -> transition(mg, s, a, sâ€²),
        (s, a) -> joint_reward(mg, s, a)
    )
end

function PredatorPreyHexWorldMG(hexes::Vector{Tuple{Int,Int}},
                                r_bump_border::Float64,
                                p_intended::Float64,
                                Î³::Float64)
    hexWorld = HexWorldMDP(hexes,
                           r_bump_border,
                           p_intended,
                           Dict{Tuple{Int64,Int64},Float64}(),
                           Î³)
    mdp = hexWorld.mdp
    return PredatorPreyHexWorldMG(hexes, mdp)
end

# const CirclePredatorPreyHexWorld = PredatorPreyHexWorldMG(
#     [
#      (-1, 2), (0, 2),
#      (-1, 1), (1, 1),
#      (0, 0), (1, 0),
#      ],
#     HexWorldRBumpBorder,
#     HexWorldPIntended,
#     0.95
# )

function CirclePredatorPreyHexWorld()
    CirclePredatorPreyHexWorld = PredatorPreyHexWorldMG(
        [
         (-1, 2), (0, 2), (1, 2),
         (-1, 1), (1, 1), (3, 1), (4, 1),
         (0, 0), (1, 0), (2, 0), (3, 0), (4, 0),
         ],
        HexWorldRBumpBorder,
        HexWorldPIntended,
        0.95
    )
    return CirclePredatorPreyHexWorld
end

# const PredatorPreyHexWorld = PredatorPreyHexWorldMG(
#     [
#      (-1, 2), (0, 2), (1, 2),
#      (-1, 1), (1, 1), (3, 1), (4, 1),
#      (0, 0), (1, 0), (2, 0), (3, 0), (4, 0),
#      ],
#     HexWorldRBumpBorder,
#     HexWorldPIntended,
#     0.95
# )

function PredatorPreyHexWorld()
    PredatorPreyHexWorld = PredatorPreyHexWorldMG(
        [
         (-1, 2), (0, 2), (1, 2),
         (-1, 1), (1, 1), (3, 1), (4, 1),
         (0, 0), (1, 0), (2, 0), (3, 0), (4, 0),
         ],
        HexWorldRBumpBorder,
        HexWorldPIntended,
        0.95
    )
    return PredatorPreyHexWorld
end
