#struct of the policy
include("visual.jl")
struct ValueFunctionPolicy
    mdp::MDP
    U::Vector{Float64}
end

# lookahead return value for each action (a) at state (s)
function lookahead(mdp::MDP, U::Vector{Float64}, s::Int64, a::Int64)
    ğ’®, T, R, Î³ = mdp.ğ’®, mdp.T, mdp.R, mdp.Î³
    return R[s, a] + Î³ * sum(T[s, a, sâ€²] * U[sâ€²] for sâ€² in ğ’®)
end

#search for the policy (action should go)
function greedy(mdp::MDP, U::Vector{Float64}, s)
    u, a = findmax(a -> lookahead(mdp, U, s, a), mdp.ğ’œ)
    return (a = a, u = u)
end

#lamdba expression with type of function is ValueFunctionPolicy
#the argument is a state (it is a number)
(policy::ValueFunctionPolicy)(s) = greedy(policy.mdp, policy.U, s).a # tra ve so nguyen


#duyá»‡t qua nhiá»u láº§n vÃ  tráº£ vá» káº¿t quáº£ máº£ng U
function iterative_policy_evaluation(mdp::MDP, policy, k_max)
    ğ’® = mdp.ğ’®
    U = [0.0 for s in ğ’®]
    for k in 1:k_max
        U = [lookahead(mdp, U, s, policy(s)) for s in ğ’®]
    end
    return U
end

function policy_evalation(mdp::MDP,policy)
    ğ’®,R,T,Î³=mdp.ğ’®,mdp.R,mdp.T,mdp.Î³
    Râ€²=[R[s,policy(s)] for s in ğ’®]
    Tâ€²=[T(s,policy(s),sâ€²) for s in ğ’®,sâ€² in ğ’®]
    I=Matrix{Int}(I,length(Râ€²),length(Râ€²))
    return (I-Î³*Tâ€²)\Râ€²
end

#call this function in main to solve this problem
function Solve(mdp::MDP, policy, k_max)
    ğ’® = mdp.ğ’®
    hexworld=HexWorld()
    U=[0.0 for s in ğ’®]
    for k = 1:k_max
        # println(k)
        U = iterative_policy_evaluation(mdp, policy, k_max)
        policyâ€² = ValueFunctionPolicy(mdp, U)
        # println("U: $U")
        actions=[policyâ€²(s) for s in ğ’®]
        visualiseHexworld("src/hexworld/visualization/iteration_$k.png",hexworld.hexes,actions,U)
        if all(policy(s) == policyâ€²(s) for s in ğ’®)
            break
        end
        policy = policyâ€²
    end
    return [policy(s) for s in ğ’®]
end



